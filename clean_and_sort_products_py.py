# -*- coding: utf-8 -*-
"""clean_and_sort_products.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hXCOu0nCG97y--rEb2mGBHWzpY75w1PJ
"""

import pandas as pd
import os
from datetime import datetime

# === CONFIGURATION ===
INPUT_CSV = "sample_input.csv"
OUTPUT_FOLDER = "output"
EXPLICIT_WORDS = ["badword"]  # Add more as needed
KEYWORDS_ORDER = ["shirt", "trouser"]  # Define sort priority

# === CLEANING FUNCTIONS ===

def is_valid_wpid(wpid):
    return isinstance(wpid, str) and wpid.isalnum() and len(wpid) >= 5

def contains_explicit(content, explicit_words):
    return any(word.lower() in content.lower() for word in explicit_words)

def remove_quotes(value):
    if isinstance(value, str):
        return value.replace('"', "")
    return value

def reorder_by_keywords(df, column, keywords):
    matched = pd.DataFrame()
    for keyword in keywords:
        match = df[df[column].str.contains(keyword, case=False, na=False)]
        matched = pd.concat([matched, match])
        df = df.drop(match.index)
    unmatched = df.sort_values(by=column)
    return pd.concat([matched, unmatched])

# === MAIN PROCESS ===

def clean_product_data(input_csv, output_dir, explicit_words, keywords):
    os.makedirs(output_dir, exist_ok=True)
    df = pd.read_csv(input_csv)

    # Track issues
    issues = {"invalid_wpid": [], "explicit": [], "duplicates": []}

    # Remove rows with invalid WPIDs
    valid_wpid_mask = df["WPID"].apply(is_valid_wpid)
    issues["invalid_wpid"] = df[~valid_wpid_mask]
    df = df[valid_wpid_mask]

    # Remove explicit content
    explicit_mask = df["Product Name"].apply(lambda x: contains_explicit(x, explicit_words))
    issues["explicit"] = df[explicit_mask]
    df = df[~explicit_mask]

    # Remove quotes from image URLs
    for col in ["Image URL1", "Image URL2", "Image URL3"]:
        df[col] = df[col].apply(remove_quotes)

    # Remove duplicates based on WPID + Item ID
    df_before_dupes = df.copy()
    df = df.drop_duplicates(subset=["WPID", "Item ID"], keep="first")
    issues["duplicates"] = df_before_dupes[~df_before_dupes.index.isin(df.index)]

    # Sort by keywords
    df = reorder_by_keywords(df, "Product Name", keywords)

    # Save outputs
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    df.to_csv(f"{output_dir}/cleaned_data_{timestamp}.csv", index=False)

    # Save each issue in a separate file
    for reason, data in issues.items():
        if not data.empty:
            data.to_csv(f"{output_dir}/rejected_{reason}_{timestamp}.csv", index=False)

    print("âœ… Cleaning complete.")
    print(f"Cleaned data saved to: cleaned_data_{timestamp}.csv")
    for reason in issues:
        print(f"Rejected {reason}: {len(issues[reason])} rows")

# === RUN SCRIPT ===
if __name__ == "__main__":
    clean_product_data(INPUT_CSV, OUTPUT_FOLDER, EXPLICIT_WORDS, KEYWORDS_ORDER)